---
title: "Introduction to Statistical Learning Chapter 7 Problem 6"
author: "Robert Smith"
date: "8/3/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Exercises

##Applied

6. In this exercise, you will further analyze the Wage data set considered throughout this chapter.

(a) Perform polynomial regression to predict `wage` using `age`. Use cross-validation to select the optimal degree d for the polynomial. What degree was chosen, and how does this compare to the results of hypothesis testing using ANOVA? Make a plot of the resulting polynomial fit to the data.

```{r,echo=T}
library(ISLR);library(boot)
data(Wage)

#Perform Cross-Validation
cv.errors<-rep(NA,10)
for (i in 1:10){
glm.fit<-glm(wage~poly(age,i),data=Wage)
set.seed(1234)
cv.glm.mod=cv.glm(Wage,glm.fit,K=10)
cv.errors[i]<-cv.glm.mod$delta[2]
}

#Plot Cross-Validated Errors
index<-which.min(cv.errors)
plot(cv.errors,type="l")
points(index,cv.errors[index],col="red",cex=2,pch=20)

#Calculate ANOVA
fit.1<-lm(wage~poly(age,1),data=Wage)
fit.2<-lm(wage~poly(age,2),data=Wage)
fit.3<-lm(wage~poly(age,3),data=Wage)
fit.4<-lm(wage~poly(age,4),data=Wage)
fit.5<-lm(wage~poly(age,5),data=Wage)
fit.6<-lm(wage~poly(age,6),data=Wage)
fit.7<-lm(wage~poly(age,7),data=Wage)
fit.8<-lm(wage~poly(age,8),data=Wage)
fit.9<-lm(wage~poly(age,9),data=Wage)
fit.10<-lm(wage~poly(age,10),data=Wage)
anova.obj<-anova(fit.1,fit.2,fit.3,fit.4,fit.5,fit.6,fit.7,fit.8,fit.9,fit.10)
```
  
Results of cross-validation and ANOVA yield similar results. A fourth degree polynomial seems to be the best fit. 
```{r,echo=T}
par(mfrow=c(1,1),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
agelims=range(Wage$age)
age.grid=seq(from=agelims[1],to=agelims[2])
pred<-predict(fit.3,newdata=list(age=age.grid),se=TRUE)
se.bands<-cbind(pred$fit+2*pred$se.fit,pred$fit-2*pred$se.fit)
plot(Wage$age,Wage$wage,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=TRUE)
lines(age.grid,pred$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
```

(b) Fit a step function to predict `wage` using `age`, and perform cross-validation to choose the optimal number of cuts. Make a plot of the fit obtained. 
```{r,echo=T}
#Perform Cross-Validation
cv.errors<-rep(NA,10)
for (i in 2:10){
  Wage$age.cut<-cut(Wage$age,i)
  glm.fit<-glm(wage~age.cut,data=Wage)
  set.seed(1234)
  cv.glm.mod=cv.glm(Wage,glm.fit,K=10)
  cv.errors[i]<-cv.glm.mod$delta[2]
}

#Plot Cross-Validated Errors
index<-which.min(cv.errors)
plot(cv.errors,type="l")
points(index,cv.errors[index],col="red",cex=2,pch=20) #Optimal Value at n=8
```

Minimum cross-validated error at 8 cuts. Let's plot the resulting model:  
```{r,echo=T}
par(mfrow=c(1,1),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
glm.fit<-glm(wage~cut(age,8),data=Wage)
agelims=range(Wage$age)
age.grid=seq(from=agelims[1],to=agelims[2])
pred<-predict(glm.fit,newdata=list(age=age.grid),se=TRUE)
se.bands<-cbind(pred$fit+2*pred$se.fit,pred$fit-2*pred$se.fit)
plot(Wage$age,Wage$wage,cex=.5,col="darkgrey")
title("8-Cut Step Function Model",outer=TRUE)
lines(age.grid,pred$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
```